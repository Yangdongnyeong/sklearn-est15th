{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# ğŸ“Š Red Wine Quality ë°ì´í„°ì…‹ ì†Œê°œ\n",
    "\n",
    "## ë°ì´í„°ì…‹ ê°œìš”\n",
    "| í•­ëª© | ë‚´ìš© |\n",
    "|------|------|\n",
    "| **ì¶œì²˜** | UCI Machine Learning Repository |\n",
    "| **ì œê³µ** | Kaggle ([uciml/red-wine-quality-cortez-et-al-2009](https://www.kaggle.com/datasets/uciml/red-wine-quality-cortez-et-al-2009)) |\n",
    "| **ë¼ì´ì„ ìŠ¤** | Open Database License (ODbL 1.0) |\n",
    "| **íŒŒì¼ í˜•ì‹** | CSV |\n",
    "\n",
    "## ë°ì´í„°ì…‹ ì„¤ëª…\n",
    "ì´ ë°ì´í„°ì…‹ì€ í¬ë¥´íˆ¬ê°ˆ \"Vinho Verde\" ë ˆë“œ ì™€ì¸ì˜ **ë¬¼ë¦¬í™”í•™ì  íŠ¹ì„±**ê³¼ **ê´€ëŠ¥ í’ˆì§ˆ í‰ê°€** ë°ì´í„°ë¥¼ í¬í•¨í•©ë‹ˆë‹¤. í”„ë¼ì´ë²„ì‹œ ë° ë¬¼ë¥˜ ì œí•œìœ¼ë¡œ ì¸í•´ í¬ë„ í’ˆì¢…, ë¸Œëœë“œ, ê°€ê²© ì •ë³´ëŠ” í¬í•¨ë˜ì–´ ìˆì§€ ì•ŠìŠµë‹ˆë‹¤.\n",
    "\n",
    "**íŠ¹ì§•:**\n",
    "- **ë¶„ë¥˜(Classification)** ë° **íšŒê·€(Regression)** ëª¨ë‘ ê°€ëŠ¥\n",
    "- í´ë˜ìŠ¤ ë¶ˆê· í˜• ì¡´ì¬ (ëŒ€ë¶€ë¶„ ì¤‘ê°„ í’ˆì§ˆ, ê·¹ë‹¨ì  í’ˆì§ˆì€ ì ìŒ)\n",
    "- ì´ì§„ ë¶„ë¥˜(Good/Bad)ë¡œ ë³€í™˜í•˜ì—¬ ë¶„ì„ ê¶Œì¥\n",
    "\n",
    "---\n",
    "\n",
    "## ì…ë ¥ ë³€ìˆ˜ (Input Variables) - ë¬¼ë¦¬í™”í•™ì  íŠ¹ì„±\n",
    "\n",
    "| # | ë³€ìˆ˜ëª… | ì„¤ëª… |\n",
    "|---|--------|------|\n",
    "| 1 | **fixed acidity** | ê³ ì • ì‚°ë„ - ë¹„íœ˜ë°œì„± ì‚°(ì£¼ì„ì‚° ë“±)ì˜ ë†ë„ (g/dmÂ³) |\n",
    "| 2 | **volatile acidity** | íœ˜ë°œì„± ì‚°ë„ - ì•„ì„¸íŠ¸ì‚° ë†ë„, ë„ˆë¬´ ë†’ìœ¼ë©´ ì‹ì´ˆ ë§› ë°œìƒ (g/dmÂ³) |\n",
    "| 3 | **citric acid** | êµ¬ì—°ì‚° - ì†ŒëŸ‰ ì²¨ê°€ ì‹œ ì‹ ì„ í•¨ê³¼ í’ë¯¸ í–¥ìƒ (g/dmÂ³) |\n",
    "| 4 | **residual sugar** | ì”ë¥˜ ë‹¹ë¶„ - ë°œíš¨ í›„ ë‚¨ì€ ë‹¹ë¶„, 45g/L ì´ìƒì´ë©´ ë‹¨ë§› ì™€ì¸ (g/dmÂ³) |\n",
    "| 5 | **chlorides** | ì—¼í™”ë¬¼ - ì™€ì¸ì˜ ì—¼ë¶„ í•¨ëŸ‰ (g/dmÂ³) |\n",
    "| 6 | **free sulfur dioxide** | ìœ ë¦¬ ì´ì‚°í™”í™© - ë¯¸ìƒë¬¼ ì„±ì¥ ì–µì œ ë° ì‚°í™” ë°©ì§€ (mg/dmÂ³) |\n",
    "| 7 | **total sulfur dioxide** | ì´ ì´ì‚°í™”í™© - ìœ ë¦¬ ë° ê²°í•© í˜•íƒœì˜ SOâ‚‚ ì´í•© (mg/dmÂ³) |\n",
    "| 8 | **density** | ë°€ë„ - ì•Œì½”ì˜¬ê³¼ ë‹¹ë¶„ í•¨ëŸ‰ì— ë”°ë¼ ê²°ì • (g/cmÂ³) |\n",
    "| 9 | **pH** | pH - ì‚°ì„±ë„ ì²™ë„ (0=ë§¤ìš° ì‚°ì„± ~ 14=ë§¤ìš° ì—¼ê¸°ì„±) |\n",
    "| 10 | **sulphates** | í™©ì‚°ì—¼ - ì™€ì¸ ì²¨ê°€ì œ, SOâ‚‚ ìˆ˜ì¤€ì— ê¸°ì—¬ (g/dmÂ³) |\n",
    "| 11 | **alcohol** | ì•Œì½”ì˜¬ - ì™€ì¸ì˜ ì•Œì½”ì˜¬ í•¨ëŸ‰ (% vol) |\n",
    "\n",
    "---\n",
    "\n",
    "## ì¶œë ¥ ë³€ìˆ˜ (Target Variable)\n",
    "\n",
    "| ë³€ìˆ˜ëª… | ì„¤ëª… | ë²”ìœ„ |\n",
    "|--------|------|------|\n",
    "| **quality** | ê´€ëŠ¥ í’ˆì§ˆ ì ìˆ˜ (ì†Œë¯ˆë¦¬ì— í‰ê°€) | 0 ~ 10 |\n",
    "\n",
    "---\n",
    "\n",
    "## ë¶„ì„ ì ‘ê·¼ ë°©ë²•\n",
    "\n",
    "### 1. íšŒê·€ ë¶„ì„ (Regression)\n",
    "- í’ˆì§ˆ ì ìˆ˜(0-10)ë¥¼ ì—°ì†í˜• ë³€ìˆ˜ë¡œ ì˜ˆì¸¡\n",
    "\n",
    "### 2. ë¶„ë¥˜ ë¶„ì„ (Classification)\n",
    "í’ˆì§ˆ ì ìˆ˜ë¥¼ ì´ì§„ ë³€ìˆ˜ë¡œ ë³€í™˜:\n",
    "- **Quality â‰¥ 6** â†’ Good (1)\n",
    "- **Quality < 6** â†’ Bad (0)\n",
    "\n",
    "> ğŸ’¡ **ì°¸ê³ **: Decision Tree ê¸°ë°˜ ì•Œê³ ë¦¬ì¦˜ìœ¼ë¡œ ì•½ **AUC 0.88** ë‹¬ì„± ê°€ëŠ¥\n",
    "\n",
    "---\n",
    "\n",
    "## ì¸ìš© (Citation)\n",
    "```\n",
    "P. Cortez, A. Cerdeira, F. Almeida, T. Matos and J. Reis. \n",
    "Modeling wine preferences by data mining from physicochemical properties. \n",
    "In Decision Support Systems, Elsevier, 47(4):547-553, 2009.\n",
    "```\n",
    "\n",
    "---"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Red Wine Quality Analysis\n",
    "## Regression & Classification ëª¨ë¸ë§\n",
    "\n",
    "### í•™ìŠµ ëª©í‘œ\n",
    "1. Kaggle APIë¥¼ ì‚¬ìš©í•˜ì—¬ ë°ì´í„°ì…‹ ë‹¤ìš´ë¡œë“œ\n",
    "2. íƒìƒ‰ì  ë°ì´í„° ë¶„ì„(EDA) ë° ì‹œê°í™”\n",
    "3. Regression ëª¨ë¸ë¡œ ì™€ì¸ í’ˆì§ˆ ì ìˆ˜ ì˜ˆì¸¡\n",
    "4. Classification ëª¨ë¸ë¡œ ì™€ì¸ í’ˆì§ˆ ë“±ê¸‰ ë¶„ë¥˜\n",
    "5. ëª¨ë¸ ì„±ëŠ¥ í‰ê°€ ë° ë¹„êµ\n",
    "\n",
    "### ë°ì´í„°ì…‹ ì •ë³´\n",
    "- **ì¶œì²˜**: UCI Machine Learning Repository (Kaggle)\n",
    "- **íŠ¹ì„±**: 11ê°œì˜ ë¬¼ë¦¬í™”í•™ì  íŠ¹ì„± (ì‚°ë„, ë‹¹ë„, pH ë“±)\n",
    "- **íƒ€ê²Ÿ**: quality (0-10 ì ìˆ˜)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---\n",
    "## 1. í™˜ê²½ ì„¤ì • ë° Kaggle ë°ì´í„° ë‹¤ìš´ë¡œë“œ"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# í•„ìš”í•œ íŒ¨í‚¤ì§€ ì„¤ì¹˜ (ì²˜ìŒ í•œ ë²ˆë§Œ ì‹¤í–‰)\n",
    "# !pip install kaggle pandas numpy matplotlib seaborn scikit-learn xgboost"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from dotenv import load_dotenv\n",
    "# .envë¡œ ë¶€í„° íŒŒì¼ì„ ì½ìœ¼ë©´ Trueê°€ ì¶œë ¥\n",
    "print(load_dotenv())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import zipfile\n",
    "\n",
    "from kaggle.api.kaggle_api_extended import KaggleApi\n",
    "\n",
    "# Kaggle API ì¸ì¦\n",
    "api = KaggleApi()\n",
    "api.authenticate()\n",
    "\n",
    "print(\"Kaggle API ì¸ì¦ ì„±ê³µ!\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# ë°ì´í„°ì…‹ ë‹¤ìš´ë¡œë“œ\n",
    "dataset_name = 'uciml/red-wine-quality-cortez-et-al-2009'\n",
    "download_path = './data'\n",
    "\n",
    "# ë‹¤ìš´ë¡œë“œ í´ë” ìƒì„±\n",
    "os.makedirs(download_path, exist_ok=True)\n",
    "\n",
    "# ë°ì´í„°ì…‹ ë‹¤ìš´ë¡œë“œ ë° ì••ì¶• í•´ì œ\n",
    "api.dataset_download_files(dataset_name, path=download_path, unzip=True)\n",
    "\n",
    "print(f\"ë°ì´í„°ì…‹ ë‹¤ìš´ë¡œë“œ ì™„ë£Œ: {download_path}\")\n",
    "print(\"ë‹¤ìš´ë¡œë“œëœ íŒŒì¼:\", os.listdir(download_path))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---\n",
    "## 2. ë¼ì´ë¸ŒëŸ¬ë¦¬ ì„í¬íŠ¸ ë° ë°ì´í„° ë¡œë“œ"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# ê¸°ë³¸ ë¼ì´ë¸ŒëŸ¬ë¦¬\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "import warnings\n",
    "warnings.filterwarnings('ignore')\n",
    "\n",
    "# ì‹œê°í™” ì„¤ì •\n",
    "plt.style.use('seaborn-v0_8-whitegrid')\n",
    "plt.rcParams['figure.figsize'] = (12, 6)\n",
    "plt.rcParams['font.size'] = 12\n",
    "plt.rcParams['axes.unicode_minus'] = False\n",
    "\n",
    "# ì „ì²˜ë¦¬ ë° ëª¨ë¸ë§\n",
    "from sklearn.model_selection import train_test_split, cross_val_score, GridSearchCV\n",
    "from sklearn.preprocessing import StandardScaler, LabelEncoder\n",
    "from sklearn.metrics import (mean_squared_error, mean_absolute_error, r2_score,\n",
    "                             accuracy_score, classification_report, confusion_matrix,\n",
    "                             roc_auc_score, roc_curve, precision_recall_curve)\n",
    "\n",
    "# Regression ëª¨ë¸\n",
    "from sklearn.linear_model import LinearRegression, Ridge, Lasso, ElasticNet\n",
    "from sklearn.tree import DecisionTreeRegressor\n",
    "from sklearn.ensemble import RandomForestRegressor, GradientBoostingRegressor\n",
    "from sklearn.svm import SVR\n",
    "from xgboost import XGBRegressor\n",
    "\n",
    "# Classification ëª¨ë¸\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.tree import DecisionTreeClassifier\n",
    "from sklearn.ensemble import RandomForestClassifier, GradientBoostingClassifier\n",
    "from sklearn.svm import SVC\n",
    "from sklearn.neighbors import KNeighborsClassifier\n",
    "from xgboost import XGBClassifier\n",
    "\n",
    "print(\"ë¼ì´ë¸ŒëŸ¬ë¦¬ ì„í¬íŠ¸ ì™„ë£Œ!\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# ë°ì´í„° ë¡œë“œ\n",
    "df = pd.read_csv('./data/winequality-red.csv')\n",
    "\n",
    "print(f\"ë°ì´í„° í¬ê¸°: {df.shape}\")\n",
    "print(f\"í–‰: {df.shape[0]}, ì—´: {df.shape[1]}\")\n",
    "df.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---\n",
    "## 3. íƒìƒ‰ì  ë°ì´í„° ë¶„ì„ (EDA)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 3.1 ê¸°ë³¸ ì •ë³´ í™•ì¸"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# ë°ì´í„° ì •ë³´\n",
    "print(\"=\" * 50)\n",
    "print(\"ë°ì´í„° íƒ€ì… ë° ê²°ì¸¡ì¹˜\")\n",
    "print(\"=\" * 50)\n",
    "df.info()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# ê¸°ìˆ  í†µê³„ëŸ‰\n",
    "print(\"\\nê¸°ìˆ  í†µê³„ëŸ‰:\")\n",
    "df.describe().round(3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# ê²°ì¸¡ì¹˜ í™•ì¸\n",
    "print(\"\\nê²°ì¸¡ì¹˜ ê°œìˆ˜:\")\n",
    "print(df.isnull().sum())\n",
    "print(f\"\\nì „ì²´ ê²°ì¸¡ì¹˜: {df.isnull().sum().sum()}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# ì¤‘ë³µ ë°ì´í„° í™•ì¸\n",
    "duplicates = df.duplicated().sum()\n",
    "print(f\"ì¤‘ë³µ í–‰ ê°œìˆ˜: {duplicates}\")\n",
    "\n",
    "# ì¤‘ë³µ ì œê±° (ì„ íƒì )\n",
    "# df = df.drop_duplicates()\n",
    "# print(f\"ì¤‘ë³µ ì œê±° í›„ ë°ì´í„° í¬ê¸°: {df.shape}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 3.2 íƒ€ê²Ÿ ë³€ìˆ˜ (quality) ë¶„ì„"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# í’ˆì§ˆ ì ìˆ˜ ë¶„í¬\n",
    "print(\"í’ˆì§ˆ ì ìˆ˜ ë¶„í¬:\")\n",
    "print(df['quality'].value_counts().sort_index())\n",
    "\n",
    "fig, axes = plt.subplots(1, 2, figsize=(14, 5))\n",
    "\n",
    "# íˆìŠ¤í† ê·¸ë¨\n",
    "axes[0].hist(df['quality'], bins=range(3, 10), edgecolor='black', alpha=0.7, color='darkred')\n",
    "axes[0].set_xlabel('Quality Score')\n",
    "axes[0].set_ylabel('Count')\n",
    "axes[0].set_title('Distribution of Wine Quality Scores')\n",
    "axes[0].set_xticks(range(3, 9))\n",
    "\n",
    "# ë§‰ëŒ€ ê·¸ë˜í”„\n",
    "quality_counts = df['quality'].value_counts().sort_index()\n",
    "bars = axes[1].bar(quality_counts.index, quality_counts.values, color='darkred', edgecolor='black', alpha=0.7)\n",
    "axes[1].set_xlabel('Quality Score')\n",
    "axes[1].set_ylabel('Count')\n",
    "axes[1].set_title('Wine Quality Distribution')\n",
    "\n",
    "# ë§‰ëŒ€ ìœ„ì— ê°’ í‘œì‹œ\n",
    "for bar, count in zip(bars, quality_counts.values):\n",
    "    axes[1].text(bar.get_x() + bar.get_width()/2, bar.get_height() + 5, \n",
    "                 str(count), ha='center', va='bottom', fontsize=10)\n",
    "\n",
    "plt.tight_layout()\n",
    "plt.show()\n",
    "\n",
    "print(f\"\\ní’ˆì§ˆ ì ìˆ˜ ë²”ìœ„: {df['quality'].min()} ~ {df['quality'].max()}\")\n",
    "print(f\"í‰ê·  í’ˆì§ˆ: {df['quality'].mean():.2f}\")\n",
    "print(f\"ì¤‘ì•™ê°’: {df['quality'].median()}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 3.3 íŠ¹ì„± ë¶„í¬ ì‹œê°í™”"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# ëª¨ë“  íŠ¹ì„±ì˜ ë¶„í¬ (íˆìŠ¤í† ê·¸ë¨ + KDE)\n",
    "fig, axes = plt.subplots(4, 3, figsize=(15, 16))\n",
    "axes = axes.flatten()\n",
    "\n",
    "for idx, col in enumerate(df.columns):\n",
    "    axes[idx].hist(df[col], bins=30, edgecolor='black', alpha=0.7, color='steelblue', density=True)\n",
    "    df[col].plot(kind='kde', ax=axes[idx], color='darkred', linewidth=2)\n",
    "    axes[idx].set_title(f'{col}', fontsize=11)\n",
    "    axes[idx].set_xlabel('')\n",
    "\n",
    "plt.tight_layout()\n",
    "plt.suptitle('Distribution of All Features', y=1.02, fontsize=14, fontweight='bold')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# ë°•ìŠ¤í”Œë¡¯ìœ¼ë¡œ ì´ìƒì¹˜ í™•ì¸\n",
    "fig, axes = plt.subplots(4, 3, figsize=(15, 14))\n",
    "axes = axes.flatten()\n",
    "\n",
    "for idx, col in enumerate(df.columns):\n",
    "    sns.boxplot(data=df, y=col, ax=axes[idx], color='lightcoral')\n",
    "    axes[idx].set_title(f'{col}')\n",
    "\n",
    "plt.tight_layout()\n",
    "plt.suptitle('Boxplots - Outlier Detection', y=1.02, fontsize=14, fontweight='bold')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 3.4 ìƒê´€ê´€ê³„ ë¶„ì„"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# ìƒê´€ê´€ê³„ íˆíŠ¸ë§µ\n",
    "plt.figure(figsize=(12, 10))\n",
    "correlation_matrix = df.corr()\n",
    "\n",
    "mask = np.triu(np.ones_like(correlation_matrix, dtype=bool))\n",
    "sns.heatmap(correlation_matrix, mask=mask, annot=True, fmt='.2f', \n",
    "            cmap='RdBu_r', center=0, square=True, linewidths=0.5,\n",
    "            cbar_kws={'shrink': 0.8})\n",
    "plt.title('Correlation Heatmap', fontsize=14, fontweight='bold')\n",
    "plt.tight_layout()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# íƒ€ê²Ÿ ë³€ìˆ˜(quality)ì™€ì˜ ìƒê´€ê´€ê³„\n",
    "quality_corr = correlation_matrix['quality'].drop('quality').sort_values(ascending=False)\n",
    "\n",
    "plt.figure(figsize=(10, 6))\n",
    "colors = ['darkred' if x > 0 else 'steelblue' for x in quality_corr.values]\n",
    "bars = plt.barh(quality_corr.index, quality_corr.values, color=colors, edgecolor='black', alpha=0.8)\n",
    "plt.xlabel('Correlation with Quality')\n",
    "plt.title('Feature Correlation with Wine Quality', fontsize=14, fontweight='bold')\n",
    "plt.axvline(x=0, color='black', linestyle='-', linewidth=0.5)\n",
    "\n",
    "# ê°’ í‘œì‹œ\n",
    "for bar, val in zip(bars, quality_corr.values):\n",
    "    plt.text(val + 0.01 if val > 0 else val - 0.05, bar.get_y() + bar.get_height()/2,\n",
    "             f'{val:.3f}', va='center', fontsize=9)\n",
    "\n",
    "plt.tight_layout()\n",
    "plt.show()\n",
    "\n",
    "print(\"\\nQualityì™€ì˜ ìƒê´€ê´€ê³„ (ì ˆëŒ€ê°’ ê¸°ì¤€ ì •ë ¬):\")\n",
    "print(quality_corr.abs().sort_values(ascending=False))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 3.5 í’ˆì§ˆë³„ íŠ¹ì„± ë¶„í¬"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# í’ˆì§ˆë³„ ì£¼ìš” íŠ¹ì„± ë¶„í¬ (ë°”ì´ì˜¬ë¦° í”Œë¡¯)\n",
    "top_features = ['alcohol', 'volatile acidity', 'sulphates', 'citric acid']\n",
    "\n",
    "fig, axes = plt.subplots(2, 2, figsize=(14, 10))\n",
    "axes = axes.flatten()\n",
    "\n",
    "for idx, feature in enumerate(top_features):\n",
    "    sns.violinplot(data=df, x='quality', y=feature, ax=axes[idx], palette='RdBu_r')\n",
    "    axes[idx].set_title(f'{feature} by Quality', fontsize=12)\n",
    "\n",
    "plt.tight_layout()\n",
    "plt.suptitle('Top Features Distribution by Quality', y=1.02, fontsize=14, fontweight='bold')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# ì‚°ì ë„ í–‰ë ¬ (ì£¼ìš” íŠ¹ì„±)\n",
    "top_features_with_quality = ['alcohol', 'volatile acidity', 'sulphates', 'citric acid', 'quality']\n",
    "sns.pairplot(df[top_features_with_quality], hue='quality', palette='RdYlBu', \n",
    "             diag_kind='kde', plot_kws={'alpha': 0.6})\n",
    "plt.suptitle('Pairplot of Top Features', y=1.02, fontsize=14, fontweight='bold')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---\n",
    "## 4. ë°ì´í„° ì „ì²˜ë¦¬"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# íŠ¹ì„±ê³¼ íƒ€ê²Ÿ ë¶„ë¦¬\n",
    "X = df.drop('quality', axis=1)\n",
    "y_reg = df['quality']  # Regressionìš© (ì—°ì†í˜•)\n",
    "\n",
    "# Classificationìš© íƒ€ê²Ÿ ìƒì„± (ì´ì§„ ë¶„ë¥˜: 6 ì´ìƒ = Good, 6 ë¯¸ë§Œ = Bad)\n",
    "y_clf = (df['quality'] >= 6).astype(int)  # 1: Good, 0: Bad\n",
    "\n",
    "print(f\"íŠ¹ì„± ìˆ˜: {X.shape[1]}\")\n",
    "print(f\"\\nClassification íƒ€ê²Ÿ ë¶„í¬:\")\n",
    "print(f\"  Bad (0): {(y_clf == 0).sum()} ({(y_clf == 0).mean()*100:.1f}%)\")\n",
    "print(f\"  Good (1): {(y_clf == 1).sum()} ({(y_clf == 1).mean()*100:.1f}%)\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# ë°ì´í„° ë¶„í•  (Train: 80%, Test: 20%)\n",
    "X_train, X_test, y_train_reg, y_test_reg = train_test_split(\n",
    "    X, y_reg, test_size=0.2, random_state=42\n",
    ")\n",
    "\n",
    "_, _, y_train_clf, y_test_clf = train_test_split(\n",
    "    X, y_clf, test_size=0.2, random_state=42\n",
    ")\n",
    "\n",
    "print(f\"Train í¬ê¸°: {X_train.shape[0]}\")\n",
    "print(f\"Test í¬ê¸°: {X_test.shape[0]}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# íŠ¹ì„± ìŠ¤ì¼€ì¼ë§\n",
    "scaler = StandardScaler()\n",
    "X_train_scaled = scaler.fit_transform(X_train)\n",
    "X_test_scaled = scaler.transform(X_test)\n",
    "\n",
    "print(\"ìŠ¤ì¼€ì¼ë§ ì™„ë£Œ!\")\n",
    "print(f\"ìŠ¤ì¼€ì¼ë§ ì „ í‰ê· : {X_train.mean().mean():.4f}\")\n",
    "print(f\"ìŠ¤ì¼€ì¼ë§ í›„ í‰ê· : {X_train_scaled.mean():.4f}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---\n",
    "## 5. Regression ëª¨ë¸ë§\n",
    "\n",
    "ì™€ì¸ í’ˆì§ˆ ì ìˆ˜(3-8)ë¥¼ ì—°ì†í˜• ê°’ìœ¼ë¡œ ì˜ˆì¸¡í•©ë‹ˆë‹¤."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Regression ëª¨ë¸ ì •ì˜\n",
    "reg_models = {\n",
    "    'Linear Regression': LinearRegression(),\n",
    "    'Ridge': Ridge(alpha=1.0),\n",
    "    'Lasso': Lasso(alpha=0.1),\n",
    "    'ElasticNet': ElasticNet(alpha=0.1, l1_ratio=0.5),\n",
    "    'Decision Tree': DecisionTreeRegressor(random_state=42, max_depth=10),\n",
    "    'Random Forest': RandomForestRegressor(n_estimators=100, random_state=42, n_jobs=-1),\n",
    "    'Gradient Boosting': GradientBoostingRegressor(n_estimators=100, random_state=42),\n",
    "    'XGBoost': XGBRegressor(n_estimators=100, random_state=42, n_jobs=-1, verbosity=0),\n",
    "    'SVR': SVR(kernel='rbf', C=1.0)\n",
    "}\n",
    "\n",
    "print(f\"ì´ {len(reg_models)}ê°œì˜ Regression ëª¨ë¸ì„ í•™ìŠµí•©ë‹ˆë‹¤.\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Regression ëª¨ë¸ í•™ìŠµ ë° í‰ê°€\n",
    "reg_results = []\n",
    "\n",
    "for name, model in reg_models.items():\n",
    "    # SVRì€ ìŠ¤ì¼€ì¼ë§ëœ ë°ì´í„° ì‚¬ìš©\n",
    "    if name == 'SVR':\n",
    "        model.fit(X_train_scaled, y_train_reg)\n",
    "        y_pred = model.predict(X_test_scaled)\n",
    "    else:\n",
    "        model.fit(X_train, y_train_reg)\n",
    "        y_pred = model.predict(X_test)\n",
    "    \n",
    "    # í‰ê°€ ì§€í‘œ ê³„ì‚°\n",
    "    mse = mean_squared_error(y_test_reg, y_pred)\n",
    "    rmse = np.sqrt(mse)\n",
    "    mae = mean_absolute_error(y_test_reg, y_pred)\n",
    "    r2 = r2_score(y_test_reg, y_pred)\n",
    "    \n",
    "    reg_results.append({\n",
    "        'Model': name,\n",
    "        'RMSE': rmse,\n",
    "        'MAE': mae,\n",
    "        'R2': r2\n",
    "    })\n",
    "    \n",
    "    print(f\"{name:20s} | RMSE: {rmse:.4f} | MAE: {mae:.4f} | RÂ²: {r2:.4f}\")\n",
    "\n",
    "# ê²°ê³¼ ë°ì´í„°í”„ë ˆì„\n",
    "reg_results_df = pd.DataFrame(reg_results).sort_values('RMSE')\n",
    "print(\"\\n\" + \"=\"*60)\n",
    "print(\"Regression ëª¨ë¸ ì„±ëŠ¥ ìˆœìœ„ (RMSE ê¸°ì¤€):\")\n",
    "print(\"=\"*60)\n",
    "reg_results_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Regression ê²°ê³¼ ì‹œê°í™”\n",
    "fig, axes = plt.subplots(1, 3, figsize=(16, 5))\n",
    "\n",
    "# RMSE ë¹„êµ\n",
    "colors = plt.cm.RdYlGn_r(np.linspace(0.2, 0.8, len(reg_results_df)))\n",
    "axes[0].barh(reg_results_df['Model'], reg_results_df['RMSE'], color=colors, edgecolor='black')\n",
    "axes[0].set_xlabel('RMSE (ë‚®ì„ìˆ˜ë¡ ì¢‹ìŒ)')\n",
    "axes[0].set_title('RMSE Comparison', fontweight='bold')\n",
    "axes[0].invert_yaxis()\n",
    "\n",
    "# MAE ë¹„êµ\n",
    "axes[1].barh(reg_results_df['Model'], reg_results_df['MAE'], color=colors, edgecolor='black')\n",
    "axes[1].set_xlabel('MAE (ë‚®ì„ìˆ˜ë¡ ì¢‹ìŒ)')\n",
    "axes[1].set_title('MAE Comparison', fontweight='bold')\n",
    "axes[1].invert_yaxis()\n",
    "\n",
    "# RÂ² ë¹„êµ\n",
    "r2_sorted = reg_results_df.sort_values('R2', ascending=False)\n",
    "colors_r2 = plt.cm.RdYlGn(np.linspace(0.2, 0.8, len(r2_sorted)))\n",
    "axes[2].barh(r2_sorted['Model'], r2_sorted['R2'], color=colors_r2, edgecolor='black')\n",
    "axes[2].set_xlabel('RÂ² Score (ë†’ì„ìˆ˜ë¡ ì¢‹ìŒ)')\n",
    "axes[2].set_title('RÂ² Score Comparison', fontweight='bold')\n",
    "axes[2].invert_yaxis()\n",
    "\n",
    "plt.tight_layout()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 5.1 Best Regression Model - í•˜ì´í¼íŒŒë¼ë¯¸í„° íŠœë‹"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Random Forest Regressor í•˜ì´í¼íŒŒë¼ë¯¸í„° íŠœë‹\n",
    "param_grid_rf = {\n",
    "    'n_estimators': [100, 200, 300],\n",
    "    'max_depth': [5, 10, 15, None],\n",
    "    'min_samples_split': [2, 5, 10],\n",
    "    'min_samples_leaf': [1, 2, 4]\n",
    "}\n",
    "\n",
    "rf_reg = RandomForestRegressor(random_state=42, n_jobs=-1)\n",
    "grid_search_rf = GridSearchCV(rf_reg, param_grid_rf, cv=5, scoring='neg_mean_squared_error', \n",
    "                               n_jobs=-1, verbose=1)\n",
    "grid_search_rf.fit(X_train, y_train_reg)\n",
    "\n",
    "print(f\"\\nBest Parameters: {grid_search_rf.best_params_}\")\n",
    "print(f\"Best CV Score (RMSE): {np.sqrt(-grid_search_rf.best_score_):.4f}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# íŠœë‹ëœ ëª¨ë¸ë¡œ ìµœì¢… í‰ê°€\n",
    "best_rf_reg = grid_search_rf.best_estimator_\n",
    "y_pred_best = best_rf_reg.predict(X_test)\n",
    "\n",
    "print(\"Tuned Random Forest Regressor ì„±ëŠ¥:\")\n",
    "print(f\"  RMSE: {np.sqrt(mean_squared_error(y_test_reg, y_pred_best)):.4f}\")\n",
    "print(f\"  MAE: {mean_absolute_error(y_test_reg, y_pred_best):.4f}\")\n",
    "print(f\"  RÂ²: {r2_score(y_test_reg, y_pred_best):.4f}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# ì˜ˆì¸¡ vs ì‹¤ì œ ê°’ ì‹œê°í™”\n",
    "fig, axes = plt.subplots(1, 2, figsize=(14, 5))\n",
    "\n",
    "# ì‚°ì ë„\n",
    "axes[0].scatter(y_test_reg, y_pred_best, alpha=0.5, c='darkred', edgecolors='black')\n",
    "axes[0].plot([y_test_reg.min(), y_test_reg.max()], [y_test_reg.min(), y_test_reg.max()], \n",
    "             'k--', lw=2, label='Perfect Prediction')\n",
    "axes[0].set_xlabel('Actual Quality')\n",
    "axes[0].set_ylabel('Predicted Quality')\n",
    "axes[0].set_title('Actual vs Predicted (Random Forest)', fontweight='bold')\n",
    "axes[0].legend()\n",
    "\n",
    "# ì”ì°¨ ë¶„í¬\n",
    "residuals = y_test_reg - y_pred_best\n",
    "axes[1].hist(residuals, bins=30, edgecolor='black', alpha=0.7, color='steelblue')\n",
    "axes[1].axvline(x=0, color='red', linestyle='--', linewidth=2)\n",
    "axes[1].set_xlabel('Residual (Actual - Predicted)')\n",
    "axes[1].set_ylabel('Frequency')\n",
    "axes[1].set_title('Residual Distribution', fontweight='bold')\n",
    "\n",
    "plt.tight_layout()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Feature Importance (Random Forest)\n",
    "feature_importance = pd.DataFrame({\n",
    "    'Feature': X.columns,\n",
    "    'Importance': best_rf_reg.feature_importances_\n",
    "}).sort_values('Importance', ascending=True)\n",
    "\n",
    "plt.figure(figsize=(10, 6))\n",
    "plt.barh(feature_importance['Feature'], feature_importance['Importance'], \n",
    "         color='darkred', edgecolor='black', alpha=0.8)\n",
    "plt.xlabel('Feature Importance')\n",
    "plt.title('Random Forest Regressor - Feature Importance', fontweight='bold')\n",
    "plt.tight_layout()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---\n",
    "## 6. Classification ëª¨ë¸ë§\n",
    "\n",
    "ì™€ì¸ì„ Good(í’ˆì§ˆ â‰¥ 6)ê³¼ Bad(í’ˆì§ˆ < 6)ë¡œ ì´ì§„ ë¶„ë¥˜í•©ë‹ˆë‹¤."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Classification ëª¨ë¸ ì •ì˜\n",
    "clf_models = {\n",
    "    'Logistic Regression': LogisticRegression(max_iter=1000, random_state=42),\n",
    "    'KNN': KNeighborsClassifier(n_neighbors=5),\n",
    "    'Decision Tree': DecisionTreeClassifier(random_state=42, max_depth=10),\n",
    "    'Random Forest': RandomForestClassifier(n_estimators=100, random_state=42, n_jobs=-1),\n",
    "    'Gradient Boosting': GradientBoostingClassifier(n_estimators=100, random_state=42),\n",
    "    'XGBoost': XGBClassifier(n_estimators=100, random_state=42, n_jobs=-1, verbosity=0, eval_metric='logloss'),\n",
    "    'SVC': SVC(kernel='rbf', C=1.0, probability=True, random_state=42)\n",
    "}\n",
    "\n",
    "print(f\"ì´ {len(clf_models)}ê°œì˜ Classification ëª¨ë¸ì„ í•™ìŠµí•©ë‹ˆë‹¤.\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Classification ëª¨ë¸ í•™ìŠµ ë° í‰ê°€\n",
    "clf_results = []\n",
    "\n",
    "for name, model in clf_models.items():\n",
    "    # ìŠ¤ì¼€ì¼ë§ì´ í•„ìš”í•œ ëª¨ë¸\n",
    "    if name in ['Logistic Regression', 'KNN', 'SVC']:\n",
    "        model.fit(X_train_scaled, y_train_clf)\n",
    "        y_pred = model.predict(X_test_scaled)\n",
    "        y_pred_proba = model.predict_proba(X_test_scaled)[:, 1]\n",
    "    else:\n",
    "        model.fit(X_train, y_train_clf)\n",
    "        y_pred = model.predict(X_test)\n",
    "        y_pred_proba = model.predict_proba(X_test)[:, 1]\n",
    "    \n",
    "    # í‰ê°€ ì§€í‘œ ê³„ì‚°\n",
    "    accuracy = accuracy_score(y_test_clf, y_pred)\n",
    "    roc_auc = roc_auc_score(y_test_clf, y_pred_proba)\n",
    "    \n",
    "    clf_results.append({\n",
    "        'Model': name,\n",
    "        'Accuracy': accuracy,\n",
    "        'ROC-AUC': roc_auc\n",
    "    })\n",
    "    \n",
    "    print(f\"{name:20s} | Accuracy: {accuracy:.4f} | ROC-AUC: {roc_auc:.4f}\")\n",
    "\n",
    "# ê²°ê³¼ ë°ì´í„°í”„ë ˆì„\n",
    "clf_results_df = pd.DataFrame(clf_results).sort_values('ROC-AUC', ascending=False)\n",
    "print(\"\\n\" + \"=\"*60)\n",
    "print(\"Classification ëª¨ë¸ ì„±ëŠ¥ ìˆœìœ„ (ROC-AUC ê¸°ì¤€):\")\n",
    "print(\"=\"*60)\n",
    "clf_results_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Classification ê²°ê³¼ ì‹œê°í™”\n",
    "fig, axes = plt.subplots(1, 2, figsize=(14, 5))\n",
    "\n",
    "# Accuracy ë¹„êµ\n",
    "acc_sorted = clf_results_df.sort_values('Accuracy', ascending=True)\n",
    "colors = plt.cm.RdYlGn(np.linspace(0.2, 0.8, len(acc_sorted)))\n",
    "axes[0].barh(acc_sorted['Model'], acc_sorted['Accuracy'], color=colors, edgecolor='black')\n",
    "axes[0].set_xlabel('Accuracy (ë†’ì„ìˆ˜ë¡ ì¢‹ìŒ)')\n",
    "axes[0].set_title('Accuracy Comparison', fontweight='bold')\n",
    "axes[0].set_xlim(0.7, 0.85)\n",
    "\n",
    "# ROC-AUC ë¹„êµ\n",
    "auc_sorted = clf_results_df.sort_values('ROC-AUC', ascending=True)\n",
    "colors_auc = plt.cm.RdYlGn(np.linspace(0.2, 0.8, len(auc_sorted)))\n",
    "axes[1].barh(auc_sorted['Model'], auc_sorted['ROC-AUC'], color=colors_auc, edgecolor='black')\n",
    "axes[1].set_xlabel('ROC-AUC (ë†’ì„ìˆ˜ë¡ ì¢‹ìŒ)')\n",
    "axes[1].set_title('ROC-AUC Comparison', fontweight='bold')\n",
    "axes[1].set_xlim(0.75, 0.9)\n",
    "\n",
    "plt.tight_layout()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 6.1 Best Classification Model - í•˜ì´í¼íŒŒë¼ë¯¸í„° íŠœë‹"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# XGBoost Classifier í•˜ì´í¼íŒŒë¼ë¯¸í„° íŠœë‹\n",
    "param_grid_xgb = {\n",
    "    'n_estimators': [50, 100, 200],\n",
    "    'max_depth': [3, 5, 7],\n",
    "    'learning_rate': [0.01, 0.1, 0.2],\n",
    "    'subsample': [0.8, 1.0],\n",
    "    'colsample_bytree': [0.8, 1.0]\n",
    "}\n",
    "\n",
    "xgb_clf = XGBClassifier(random_state=42, n_jobs=-1, verbosity=0, eval_metric='logloss')\n",
    "grid_search_xgb = GridSearchCV(xgb_clf, param_grid_xgb, cv=5, scoring='roc_auc', \n",
    "                                n_jobs=-1, verbose=1)\n",
    "grid_search_xgb.fit(X_train, y_train_clf)\n",
    "\n",
    "print(f\"\\nBest Parameters: {grid_search_xgb.best_params_}\")\n",
    "print(f\"Best CV Score (ROC-AUC): {grid_search_xgb.best_score_:.4f}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# íŠœë‹ëœ ëª¨ë¸ë¡œ ìµœì¢… í‰ê°€\n",
    "best_xgb_clf = grid_search_xgb.best_estimator_\n",
    "y_pred_clf_best = best_xgb_clf.predict(X_test)\n",
    "y_pred_proba_best = best_xgb_clf.predict_proba(X_test)[:, 1]\n",
    "\n",
    "print(\"Tuned XGBoost Classifier ì„±ëŠ¥:\")\n",
    "print(f\"  Accuracy: {accuracy_score(y_test_clf, y_pred_clf_best):.4f}\")\n",
    "print(f\"  ROC-AUC: {roc_auc_score(y_test_clf, y_pred_proba_best):.4f}\")\n",
    "print(\"\\nClassification Report:\")\n",
    "print(classification_report(y_test_clf, y_pred_clf_best, target_names=['Bad', 'Good']))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Confusion Matrix ì‹œê°í™”\n",
    "fig, axes = plt.subplots(1, 2, figsize=(14, 5))\n",
    "\n",
    "# Confusion Matrix\n",
    "cm = confusion_matrix(y_test_clf, y_pred_clf_best)\n",
    "sns.heatmap(cm, annot=True, fmt='d', cmap='Blues', ax=axes[0],\n",
    "            xticklabels=['Bad', 'Good'], yticklabels=['Bad', 'Good'])\n",
    "axes[0].set_xlabel('Predicted')\n",
    "axes[0].set_ylabel('Actual')\n",
    "axes[0].set_title('Confusion Matrix (XGBoost)', fontweight='bold')\n",
    "\n",
    "# ROC Curve\n",
    "fpr, tpr, _ = roc_curve(y_test_clf, y_pred_proba_best)\n",
    "roc_auc = roc_auc_score(y_test_clf, y_pred_proba_best)\n",
    "\n",
    "axes[1].plot(fpr, tpr, color='darkred', lw=2, label=f'XGBoost (AUC = {roc_auc:.3f})')\n",
    "axes[1].plot([0, 1], [0, 1], color='gray', lw=1, linestyle='--', label='Random Guess')\n",
    "axes[1].set_xlabel('False Positive Rate')\n",
    "axes[1].set_ylabel('True Positive Rate')\n",
    "axes[1].set_title('ROC Curve', fontweight='bold')\n",
    "axes[1].legend(loc='lower right')\n",
    "axes[1].fill_between(fpr, tpr, alpha=0.2, color='darkred')\n",
    "\n",
    "plt.tight_layout()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# ëª¨ë“  ëª¨ë¸ì˜ ROC Curve ë¹„êµ\n",
    "plt.figure(figsize=(10, 8))\n",
    "\n",
    "for name, model in clf_models.items():\n",
    "    if name in ['Logistic Regression', 'KNN', 'SVC']:\n",
    "        y_pred_proba = model.predict_proba(X_test_scaled)[:, 1]\n",
    "    else:\n",
    "        y_pred_proba = model.predict_proba(X_test)[:, 1]\n",
    "    \n",
    "    fpr, tpr, _ = roc_curve(y_test_clf, y_pred_proba)\n",
    "    auc = roc_auc_score(y_test_clf, y_pred_proba)\n",
    "    plt.plot(fpr, tpr, lw=2, label=f'{name} (AUC = {auc:.3f})')\n",
    "\n",
    "plt.plot([0, 1], [0, 1], color='gray', lw=1, linestyle='--', label='Random Guess')\n",
    "plt.xlabel('False Positive Rate', fontsize=12)\n",
    "plt.ylabel('True Positive Rate', fontsize=12)\n",
    "plt.title('ROC Curves Comparison - All Models', fontsize=14, fontweight='bold')\n",
    "plt.legend(loc='lower right')\n",
    "plt.grid(True, alpha=0.3)\n",
    "plt.tight_layout()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Feature Importance (XGBoost Classifier)\n",
    "feature_importance_clf = pd.DataFrame({\n",
    "    'Feature': X.columns,\n",
    "    'Importance': best_xgb_clf.feature_importances_\n",
    "}).sort_values('Importance', ascending=True)\n",
    "\n",
    "plt.figure(figsize=(10, 6))\n",
    "plt.barh(feature_importance_clf['Feature'], feature_importance_clf['Importance'], \n",
    "         color='steelblue', edgecolor='black', alpha=0.8)\n",
    "plt.xlabel('Feature Importance')\n",
    "plt.title('XGBoost Classifier - Feature Importance', fontweight='bold')\n",
    "plt.tight_layout()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---\n",
    "## 7. ìµœì¢… ê²°ê³¼ ìš”ì•½"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(\"=\"*70)\n",
    "print(\"                    Red Wine Quality Analysis - ìµœì¢… ê²°ê³¼\")\n",
    "print(\"=\"*70)\n",
    "\n",
    "print(\"\\n[1] ë°ì´í„° ê°œìš”\")\n",
    "print(f\"    - ì „ì²´ ìƒ˜í”Œ ìˆ˜: {len(df)}\")\n",
    "print(f\"    - íŠ¹ì„± ìˆ˜: {X.shape[1]}\")\n",
    "print(f\"    - í’ˆì§ˆ ì ìˆ˜ ë²”ìœ„: {df['quality'].min()} ~ {df['quality'].max()}\")\n",
    "\n",
    "print(\"\\n[2] Regression ëª¨ë¸ (í’ˆì§ˆ ì ìˆ˜ ì˜ˆì¸¡)\")\n",
    "best_reg = reg_results_df.iloc[0]\n",
    "print(f\"    - Best Model: {best_reg['Model']}\")\n",
    "print(f\"    - RMSE: {best_reg['RMSE']:.4f}\")\n",
    "print(f\"    - MAE: {best_reg['MAE']:.4f}\")\n",
    "print(f\"    - RÂ²: {best_reg['R2']:.4f}\")\n",
    "\n",
    "print(\"\\n[3] Classification ëª¨ë¸ (Good/Bad ë¶„ë¥˜)\")\n",
    "best_clf = clf_results_df.iloc[0]\n",
    "print(f\"    - Best Model: {best_clf['Model']}\")\n",
    "print(f\"    - Accuracy: {best_clf['Accuracy']:.4f}\")\n",
    "print(f\"    - ROC-AUC: {best_clf['ROC-AUC']:.4f}\")\n",
    "\n",
    "print(\"\\n[4] ì£¼ìš” íŠ¹ì„± (Feature Importance)\")\n",
    "top_features = feature_importance_clf.tail(5)['Feature'].tolist()[::-1]\n",
    "print(f\"    - Top 5: {', '.join(top_features)}\")\n",
    "\n",
    "print(\"\\n\" + \"=\"*70)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# ìµœì¢… ê²°ê³¼ ì‹œê°í™”\n",
    "fig, axes = plt.subplots(1, 2, figsize=(14, 5))\n",
    "\n",
    "# Regression ê²°ê³¼\n",
    "axes[0].bar(reg_results_df['Model'], reg_results_df['R2'], color='darkred', edgecolor='black', alpha=0.8)\n",
    "axes[0].set_ylabel('RÂ² Score')\n",
    "axes[0].set_title('Regression Models - RÂ² Score', fontweight='bold')\n",
    "axes[0].tick_params(axis='x', rotation=45)\n",
    "axes[0].axhline(y=reg_results_df['R2'].max(), color='green', linestyle='--', alpha=0.7)\n",
    "\n",
    "# Classification ê²°ê³¼\n",
    "axes[1].bar(clf_results_df['Model'], clf_results_df['ROC-AUC'], color='steelblue', edgecolor='black', alpha=0.8)\n",
    "axes[1].set_ylabel('ROC-AUC Score')\n",
    "axes[1].set_title('Classification Models - ROC-AUC', fontweight='bold')\n",
    "axes[1].tick_params(axis='x', rotation=45)\n",
    "axes[1].axhline(y=clf_results_df['ROC-AUC'].max(), color='green', linestyle='--', alpha=0.7)\n",
    "\n",
    "plt.tight_layout()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---\n",
    "## 8. ê²°ë¡  ë° ì¸ì‚¬ì´íŠ¸\n",
    "\n",
    "### ì£¼ìš” ë°œê²¬ì‚¬í•­\n",
    "\n",
    "1. **ë°ì´í„° íŠ¹ì„±**\n",
    "   - ì™€ì¸ í’ˆì§ˆ ë¶„í¬ê°€ ë¶ˆê· í˜•í•¨ (ëŒ€ë¶€ë¶„ 5-6ì ì— ì§‘ì¤‘)\n",
    "   - ê²°ì¸¡ì¹˜ ì—†ìŒ, ì¼ë¶€ ì´ìƒì¹˜ ì¡´ì¬\n",
    "\n",
    "2. **ì¤‘ìš” íŠ¹ì„±**\n",
    "   - `alcohol`: í’ˆì§ˆê³¼ ê°€ì¥ ë†’ì€ ì–‘ì˜ ìƒê´€ê´€ê³„\n",
    "   - `volatile acidity`: í’ˆì§ˆê³¼ ê°€ì¥ ë†’ì€ ìŒì˜ ìƒê´€ê´€ê³„\n",
    "   - `sulphates`, `citric acid`: í’ˆì§ˆì— ê¸ì •ì  ì˜í–¥\n",
    "\n",
    "3. **ëª¨ë¸ ì„±ëŠ¥**\n",
    "   - **Regression**: ì•™ìƒë¸” ëª¨ë¸(Random Forest, XGBoost, Gradient Boosting)ì´ ì„ í˜• ëª¨ë¸ë³´ë‹¤ ìš°ìˆ˜\n",
    "   - **Classification**: XGBoostì™€ Gradient Boostingì´ ê°€ì¥ ì¢‹ì€ ì„±ëŠ¥\n",
    "\n",
    "4. **ê°œì„  ë°©í–¥**\n",
    "   - í´ë˜ìŠ¤ ë¶ˆê· í˜• í•´ê²° (SMOTE, ê°€ì¤‘ì¹˜ ì¡°ì •)\n",
    "   - ì´ìƒì¹˜ ì²˜ë¦¬\n",
    "   - íŠ¹ì„± ì—”ì§€ë‹ˆì–´ë§ (íŠ¹ì„± ê°„ ìƒí˜¸ì‘ìš©)\n",
    "   - ë” ë§ì€ ë°ì´í„° ìˆ˜ì§‘"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---\n",
    "## 9. ëª¨ë¸ ì„±ëŠ¥ ê°œì„ \n",
    "\n",
    "ìœ„ ê²°ë¡ ì—ì„œ ì œì•ˆí•œ ê°œì„  ë°©í–¥ì„ ì‹¤ì œë¡œ ì ìš©í•˜ì—¬ ëª¨ë¸ ì„±ëŠ¥ì„ í–¥ìƒì‹œì¼œ ë´…ë‹ˆë‹¤.\n",
    "\n",
    "### ê°œì„  í•­ëª©\n",
    "1. **ì´ìƒì¹˜ ì²˜ë¦¬** - IQR ê¸°ë°˜ ì´ìƒì¹˜ ìº¡í•‘(Capping)\n",
    "2. **íŠ¹ì„± ì—”ì§€ë‹ˆì–´ë§** - ë„ë©”ì¸ ì§€ì‹ ê¸°ë°˜ ìƒí˜¸ì‘ìš© ë³€ìˆ˜ ìƒì„±\n",
    "3. **í´ë˜ìŠ¤ ë¶ˆê· í˜• í•´ê²°** - SMOTE ë° class_weight ì ìš©"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 9.1 ì´ìƒì¹˜ ì²˜ë¦¬ (IQR ê¸°ë°˜ Capping)\n",
    "def cap_outliers(df, columns, multiplier=1.5):\n",
    "    \"\"\"IQR ë°©ë²•ìœ¼ë¡œ ì´ìƒì¹˜ë¥¼ ìƒí•œ/í•˜í•œê°’ìœ¼ë¡œ ëŒ€ì²´ (Capping)\"\"\"\n",
    "    df_capped = df.copy()\n",
    "    outlier_info = []\n",
    "    \n",
    "    for col in columns:\n",
    "        Q1 = df_capped[col].quantile(0.25)\n",
    "        Q3 = df_capped[col].quantile(0.75)\n",
    "        IQR = Q3 - Q1\n",
    "        lower_bound = Q1 - multiplier * IQR\n",
    "        upper_bound = Q3 + multiplier * IQR\n",
    "        \n",
    "        # ì´ìƒì¹˜ ê°œìˆ˜ í™•ì¸\n",
    "        outliers_low = (df_capped[col] < lower_bound).sum()\n",
    "        outliers_high = (df_capped[col] > upper_bound).sum()\n",
    "        \n",
    "        if outliers_low > 0 or outliers_high > 0:\n",
    "            outlier_info.append({\n",
    "                'Feature': col,\n",
    "                'Lower Outliers': outliers_low,\n",
    "                'Upper Outliers': outliers_high,\n",
    "                'Total': outliers_low + outliers_high\n",
    "            })\n",
    "        \n",
    "        # Capping ì ìš©\n",
    "        df_capped[col] = df_capped[col].clip(lower=lower_bound, upper=upper_bound)\n",
    "    \n",
    "    return df_capped, pd.DataFrame(outlier_info)\n",
    "\n",
    "# ì´ìƒì¹˜ ì²˜ë¦¬ ì ìš© (quality ì œì™¸)\n",
    "feature_columns = df.columns.drop('quality').tolist()\n",
    "df_improved, outlier_df = cap_outliers(df, feature_columns)\n",
    "\n",
    "print(\"### ì´ìƒì¹˜ ì²˜ë¦¬ ê²°ê³¼ ###\")\n",
    "print(f\"\\nì´ìƒì¹˜ê°€ ë°œê²¬ëœ íŠ¹ì„±:\")\n",
    "display(outlier_df.sort_values('Total', ascending=False))\n",
    "print(f\"\\nì²˜ë¦¬ ì „ ë°ì´í„° í¬ê¸°: {df.shape}\")\n",
    "print(f\"ì²˜ë¦¬ í›„ ë°ì´í„° í¬ê¸°: {df_improved.shape}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 9.2 íŠ¹ì„± ì—”ì§€ë‹ˆì–´ë§ (Feature Engineering)\n",
    "def create_features(df):\n",
    "    \"\"\"ë„ë©”ì¸ ì§€ì‹ ê¸°ë°˜ ìƒˆë¡œìš´ íŠ¹ì„± ìƒì„±\"\"\"\n",
    "    df_fe = df.copy()\n",
    "    \n",
    "    # 1. ì´ ì‚°ë„ (Total Acidity)\n",
    "    df_fe['total_acidity'] = df_fe['fixed acidity'] + df_fe['volatile acidity'] + df_fe['citric acid']\n",
    "    \n",
    "    # 2. ìœ ë¦¬ SO2 ë¹„ìœ¨ (Free SO2 Ratio)\n",
    "    df_fe['free_so2_ratio'] = df_fe['free sulfur dioxide'] / (df_fe['total sulfur dioxide'] + 1e-6)\n",
    "    \n",
    "    # 3. ê²°í•© SO2 (Bound SO2)\n",
    "    df_fe['bound_sulfur_dioxide'] = df_fe['total sulfur dioxide'] - df_fe['free sulfur dioxide']\n",
    "    \n",
    "    # 4. ì•Œì½”ì˜¬ ëŒ€ë¹„ ë°€ë„ (Alcohol to Density Ratio)\n",
    "    df_fe['alcohol_density_ratio'] = df_fe['alcohol'] / df_fe['density']\n",
    "    \n",
    "    # 5. í™©ì‚°ì—¼ ëŒ€ë¹„ íœ˜ë°œì„± ì‚°ë„ (Sulphates to Volatile Acidity)\n",
    "    df_fe['sulphates_volatile_ratio'] = df_fe['sulphates'] / (df_fe['volatile acidity'] + 1e-6)\n",
    "    \n",
    "    # 6. ì‚°ë„ ê· í˜• (Acidity Balance) - ê³ ì •ì‚°ë„ ëŒ€ë¹„ íœ˜ë°œì„± ì‚°ë„\n",
    "    df_fe['acidity_balance'] = df_fe['fixed acidity'] / (df_fe['volatile acidity'] + 1e-6)\n",
    "    \n",
    "    # 7. ë‹¹ë¶„ ëŒ€ë¹„ ì•Œì½”ì˜¬ (Sugar Alcohol Ratio)\n",
    "    df_fe['sugar_alcohol_ratio'] = df_fe['residual sugar'] / (df_fe['alcohol'] + 1e-6)\n",
    "    \n",
    "    # 8. ì•Œì½”ì˜¬ * í™©ì‚°ì—¼ (ìƒí˜¸ì‘ìš©)\n",
    "    df_fe['alcohol_sulphates'] = df_fe['alcohol'] * df_fe['sulphates']\n",
    "    \n",
    "    return df_fe\n",
    "\n",
    "# íŠ¹ì„± ì—”ì§€ë‹ˆì–´ë§ ì ìš©\n",
    "df_improved = create_features(df_improved)\n",
    "\n",
    "print(\"### íŠ¹ì„± ì—”ì§€ë‹ˆì–´ë§ ê²°ê³¼ ###\")\n",
    "print(f\"\\nì›ë³¸ íŠ¹ì„± ìˆ˜: 11\")\n",
    "print(f\"ìƒˆë¡œ ìƒì„±ëœ íŠ¹ì„± ìˆ˜: {df_improved.shape[1] - 12}\")  # quality ì œì™¸\n",
    "print(f\"ì „ì²´ íŠ¹ì„± ìˆ˜: {df_improved.shape[1] - 1}\")  # quality ì œì™¸\n",
    "\n",
    "new_features = ['total_acidity', 'free_so2_ratio', 'bound_sulfur_dioxide', \n",
    "                'alcohol_density_ratio', 'sulphates_volatile_ratio', \n",
    "                'acidity_balance', 'sugar_alcohol_ratio', 'alcohol_sulphates']\n",
    "print(f\"\\nìƒˆë¡œìš´ íŠ¹ì„±: {new_features}\")\n",
    "print(f\"\\nìƒˆë¡œìš´ íŠ¹ì„± í†µê³„:\")\n",
    "display(df_improved[new_features].describe().round(3))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 9.3 ê°œì„ ëœ ë°ì´í„°ë¡œ ì „ì²˜ë¦¬\n",
    "from imblearn.over_sampling import SMOTE\n",
    "\n",
    "# íŠ¹ì„±ê³¼ íƒ€ê²Ÿ ë¶„ë¦¬ (ê°œì„ ëœ ë°ì´í„°)\n",
    "X_improved = df_improved.drop('quality', axis=1)\n",
    "y_improved_reg = df_improved['quality']\n",
    "y_improved_clf = (df_improved['quality'] >= 6).astype(int)\n",
    "\n",
    "# ë°ì´í„° ë¶„í• \n",
    "X_train_imp, X_test_imp, y_train_reg_imp, y_test_reg_imp = train_test_split(\n",
    "    X_improved, y_improved_reg, test_size=0.2, random_state=42\n",
    ")\n",
    "_, _, y_train_clf_imp, y_test_clf_imp = train_test_split(\n",
    "    X_improved, y_improved_clf, test_size=0.2, random_state=42\n",
    ")\n",
    "\n",
    "# ìŠ¤ì¼€ì¼ë§\n",
    "scaler_imp = StandardScaler()\n",
    "X_train_imp_scaled = scaler_imp.fit_transform(X_train_imp)\n",
    "X_test_imp_scaled = scaler_imp.transform(X_test_imp)\n",
    "\n",
    "# SMOTE ì ìš© (Classificationìš©)\n",
    "smote = SMOTE(random_state=42)\n",
    "X_train_smote, y_train_smote = smote.fit_resample(X_train_imp_scaled, y_train_clf_imp)\n",
    "\n",
    "print(\"### 9.3 ê°œì„ ëœ ë°ì´í„° ì „ì²˜ë¦¬ ì™„ë£Œ ###\")\n",
    "print(f\"\\níŠ¹ì„± ìˆ˜: {X_improved.shape[1]}\")\n",
    "print(f\"\\nSMOTE ì ìš© ì „ í´ë˜ìŠ¤ ë¶„í¬:\")\n",
    "print(f\"  Bad (0): {(y_train_clf_imp == 0).sum()}\")\n",
    "print(f\"  Good (1): {(y_train_clf_imp == 1).sum()}\")\n",
    "print(f\"\\nSMOTE ì ìš© í›„ í´ë˜ìŠ¤ ë¶„í¬:\")\n",
    "print(f\"  Bad (0): {(y_train_smote == 0).sum()}\")\n",
    "print(f\"  Good (1): {(y_train_smote == 1).sum()}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 9.4 ê°œì„ ëœ Classification ëª¨ë¸ í•™ìŠµ ë° í‰ê°€\n",
    "print(\"### 9.4 ê°œì„ ëœ Classification ëª¨ë¸ í•™ìŠµ ###\\n\")\n",
    "\n",
    "# ê°œì„ ëœ ëª¨ë¸ ì •ì˜ (class_weight ì ìš©)\n",
    "improved_clf_models = {\n",
    "    'Logistic Regression': LogisticRegression(max_iter=1000, random_state=42, class_weight='balanced'),\n",
    "    'Random Forest': RandomForestClassifier(n_estimators=100, random_state=42, n_jobs=-1, class_weight='balanced'),\n",
    "    'Gradient Boosting': GradientBoostingClassifier(n_estimators=100, random_state=42),\n",
    "    'XGBoost': XGBClassifier(n_estimators=100, random_state=42, n_jobs=-1, verbosity=0, \n",
    "                             eval_metric='logloss', scale_pos_weight=1),\n",
    "    'SVC': SVC(kernel='rbf', C=1.0, probability=True, random_state=42, class_weight='balanced')\n",
    "}\n",
    "\n",
    "improved_clf_results = []\n",
    "\n",
    "print(\"1) class_weight='balanced' ì ìš© ëª¨ë¸:\")\n",
    "print(\"-\" * 60)\n",
    "for name, model in improved_clf_models.items():\n",
    "    if name in ['Logistic Regression', 'SVC']:\n",
    "        model.fit(X_train_imp_scaled, y_train_clf_imp)\n",
    "        y_pred = model.predict(X_test_imp_scaled)\n",
    "        y_pred_proba = model.predict_proba(X_test_imp_scaled)[:, 1]\n",
    "    else:\n",
    "        model.fit(X_train_imp, y_train_clf_imp)\n",
    "        y_pred = model.predict(X_test_imp)\n",
    "        y_pred_proba = model.predict_proba(X_test_imp)[:, 1]\n",
    "    \n",
    "    accuracy = accuracy_score(y_test_clf_imp, y_pred)\n",
    "    roc_auc = roc_auc_score(y_test_clf_imp, y_pred_proba)\n",
    "    \n",
    "    improved_clf_results.append({\n",
    "        'Model': f'{name} (class_weight)',\n",
    "        'Accuracy': accuracy,\n",
    "        'ROC-AUC': roc_auc,\n",
    "        'Method': 'class_weight'\n",
    "    })\n",
    "    print(f\"  {name:25s} | Accuracy: {accuracy:.4f} | ROC-AUC: {roc_auc:.4f}\")\n",
    "\n",
    "# SMOTE ì ìš© ëª¨ë¸ (XGBoost)\n",
    "print(\"\\n2) SMOTE ì ìš© ëª¨ë¸:\")\n",
    "print(\"-\" * 60)\n",
    "\n",
    "xgb_smote = XGBClassifier(n_estimators=200, max_depth=7, learning_rate=0.1, \n",
    "                          random_state=42, n_jobs=-1, verbosity=0, eval_metric='logloss')\n",
    "xgb_smote.fit(X_train_smote, y_train_smote)\n",
    "y_pred_smote = xgb_smote.predict(X_test_imp_scaled)\n",
    "y_pred_proba_smote = xgb_smote.predict_proba(X_test_imp_scaled)[:, 1]\n",
    "\n",
    "acc_smote = accuracy_score(y_test_clf_imp, y_pred_smote)\n",
    "auc_smote = roc_auc_score(y_test_clf_imp, y_pred_proba_smote)\n",
    "\n",
    "improved_clf_results.append({\n",
    "    'Model': 'XGBoost (SMOTE)',\n",
    "    'Accuracy': acc_smote,\n",
    "    'ROC-AUC': auc_smote,\n",
    "    'Method': 'SMOTE'\n",
    "})\n",
    "print(f\"  XGBoost (SMOTE)             | Accuracy: {acc_smote:.4f} | ROC-AUC: {auc_smote:.4f}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 9.5 ì›ë³¸ ëª¨ë¸ vs ê°œì„  ëª¨ë¸ ì„±ëŠ¥ ë¹„êµ\n",
    "print(\"### 9.5 ì›ë³¸ ëª¨ë¸ vs ê°œì„  ëª¨ë¸ ì„±ëŠ¥ ë¹„êµ ###\\n\")\n",
    "\n",
    "# ì›ë³¸ ëª¨ë¸ ê²°ê³¼ (clf_results_dfì—ì„œ ê°€ì ¸ì˜¤ê¸°)\n",
    "original_best = clf_results_df.iloc[0]  # Random Forest\n",
    "\n",
    "# ê°œì„  ëª¨ë¸ ê²°ê³¼ DataFrame\n",
    "improved_clf_df = pd.DataFrame(improved_clf_results).sort_values('ROC-AUC', ascending=False)\n",
    "improved_best = improved_clf_df.iloc[0]\n",
    "\n",
    "print(\"=\" * 70)\n",
    "print(\"                      ì„±ëŠ¥ ë¹„êµ ê²°ê³¼\")\n",
    "print(\"=\" * 70)\n",
    "print(\"\\n[ì›ë³¸ ëª¨ë¸ - Best]\")\n",
    "print(f\"  Model: {original_best['Model']}\")\n",
    "print(f\"  Accuracy: {original_best['Accuracy']:.4f}\")\n",
    "print(f\"  ROC-AUC: {original_best['ROC-AUC']:.4f}\")\n",
    "\n",
    "print(\"\\n[ê°œì„  ëª¨ë¸ - Best]\")\n",
    "print(f\"  Model: {improved_best['Model']}\")\n",
    "print(f\"  Accuracy: {improved_best['Accuracy']:.4f}\")\n",
    "print(f\"  ROC-AUC: {improved_best['ROC-AUC']:.4f}\")\n",
    "\n",
    "# ì„±ëŠ¥ í–¥ìƒë¥  ê³„ì‚°\n",
    "acc_improvement = (improved_best['Accuracy'] - original_best['Accuracy']) / original_best['Accuracy'] * 100\n",
    "auc_improvement = (improved_best['ROC-AUC'] - original_best['ROC-AUC']) / original_best['ROC-AUC'] * 100\n",
    "\n",
    "print(f\"\\n[ì„±ëŠ¥ ë³€í™”]\")\n",
    "print(f\"  Accuracy ë³€í™”: {acc_improvement:+.2f}%\")\n",
    "print(f\"  ROC-AUC ë³€í™”: {auc_improvement:+.2f}%\")\n",
    "print(\"=\" * 70)\n",
    "\n",
    "# ì‹œê°í™”\n",
    "fig, axes = plt.subplots(1, 3, figsize=(16, 5))\n",
    "\n",
    "# 1. Accuracy ë¹„êµ (ì›ë³¸ vs ê°œì„ )\n",
    "comparison_data = {\n",
    "    'Original Best\\n(Random Forest)': original_best['Accuracy'],\n",
    "    'Improved Best\\n' + improved_best['Model'].replace(' (', '\\n(').replace(')', ')'): improved_best['Accuracy']\n",
    "}\n",
    "colors = ['#3498db', '#e74c3c']\n",
    "bars1 = axes[0].bar(comparison_data.keys(), comparison_data.values(), color=colors, edgecolor='black', alpha=0.8)\n",
    "axes[0].set_ylabel('Accuracy', fontsize=12)\n",
    "axes[0].set_title('Accuracy: Original vs Improved', fontweight='bold')\n",
    "axes[0].set_ylim(0.7, 0.9)\n",
    "for bar, val in zip(bars1, comparison_data.values()):\n",
    "    axes[0].text(bar.get_x() + bar.get_width()/2, bar.get_height() + 0.005, \n",
    "                 f'{val:.4f}', ha='center', fontsize=11, fontweight='bold')\n",
    "\n",
    "# 2. ROC-AUC ë¹„êµ\n",
    "comparison_auc = {\n",
    "    'Original Best\\n(Random Forest)': original_best['ROC-AUC'],\n",
    "    'Improved Best\\n' + improved_best['Model'].replace(' (', '\\n(').replace(')', ')'): improved_best['ROC-AUC']\n",
    "}\n",
    "bars2 = axes[1].bar(comparison_auc.keys(), comparison_auc.values(), color=colors, edgecolor='black', alpha=0.8)\n",
    "axes[1].set_ylabel('ROC-AUC', fontsize=12)\n",
    "axes[1].set_title('ROC-AUC: Original vs Improved', fontweight='bold')\n",
    "axes[1].set_ylim(0.8, 0.95)\n",
    "for bar, val in zip(bars2, comparison_auc.values()):\n",
    "    axes[1].text(bar.get_x() + bar.get_width()/2, bar.get_height() + 0.005, \n",
    "                 f'{val:.4f}', ha='center', fontsize=11, fontweight='bold')\n",
    "\n",
    "# 3. ê°œì„  ëª¨ë¸ ì „ì²´ ë¹„êµ\n",
    "improved_sorted = improved_clf_df.sort_values('ROC-AUC', ascending=True)\n",
    "colors_bar = plt.cm.RdYlGn(np.linspace(0.2, 0.8, len(improved_sorted)))\n",
    "axes[2].barh(improved_sorted['Model'], improved_sorted['ROC-AUC'], color=colors_bar, edgecolor='black')\n",
    "axes[2].axvline(x=original_best['ROC-AUC'], color='red', linestyle='--', linewidth=2, \n",
    "                label=f\"Original Best ({original_best['ROC-AUC']:.4f})\")\n",
    "axes[2].set_xlabel('ROC-AUC', fontsize=12)\n",
    "axes[2].set_title('Improved Models Comparison', fontweight='bold')\n",
    "axes[2].legend(loc='lower right')\n",
    "axes[2].set_xlim(0.8, 0.95)\n",
    "\n",
    "plt.tight_layout()\n",
    "plt.show()\n",
    "\n",
    "# ìƒì„¸ ê²°ê³¼í‘œ ì¶œë ¥\n",
    "print(\"\\n### ê°œì„  ëª¨ë¸ ì „ì²´ ê²°ê³¼ ###\")\n",
    "display(improved_clf_df[['Model', 'Accuracy', 'ROC-AUC', 'Method']].reset_index(drop=True))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---\n",
    "## 9.6 ê°œì„  ê²°ê³¼ ìš”ì•½\n",
    "\n",
    "### ì ìš©í•œ ê°œì„  ê¸°ë²•\n",
    "\n",
    "| ê¸°ë²• | ì„¤ëª… | íš¨ê³¼ |\n",
    "|------|------|------|\n",
    "| **ì´ìƒì¹˜ ì²˜ë¦¬ (Capping)** | IQR ê¸°ë°˜ìœ¼ë¡œ ê·¹ë‹¨ê°’ì„ ìƒ/í•˜í•œìœ¼ë¡œ ëŒ€ì²´ | ëª¨ë¸ ì•ˆì •ì„± í–¥ìƒ |\n",
    "| **íŠ¹ì„± ì—”ì§€ë‹ˆì–´ë§** | ë„ë©”ì¸ ì§€ì‹ ê¸°ë°˜ 8ê°œ ì‹ ê·œ íŠ¹ì„± ìƒì„± | íŠ¹ì„± í‘œí˜„ë ¥ ì¦ê°€ |\n",
    "| **class_weight='balanced'** | í´ë˜ìŠ¤ ë¹„ìœ¨ì— ë”°ë¥¸ ê°€ì¤‘ì¹˜ ìë™ ì¡°ì • | ì†Œìˆ˜ í´ë˜ìŠ¤ ì˜ˆì¸¡ë ¥ í–¥ìƒ |\n",
    "| **SMOTE** | ì†Œìˆ˜ í´ë˜ìŠ¤ í•©ì„± ì˜¤ë²„ìƒ˜í”Œë§ | í´ë˜ìŠ¤ ê· í˜• í™•ë³´ |\n",
    "\n",
    "### ìƒˆë¡œ ìƒì„±ëœ íŠ¹ì„±\n",
    "1. `total_acidity` - ì´ ì‚°ë„ (fixed + volatile + citric)\n",
    "2. `free_so2_ratio` - ìœ ë¦¬ SO2 ë¹„ìœ¨\n",
    "3. `bound_sulfur_dioxide` - ê²°í•© SO2\n",
    "4. `alcohol_density_ratio` - ì•Œì½”ì˜¬/ë°€ë„ ë¹„ìœ¨\n",
    "5. `sulphates_volatile_ratio` - í™©ì‚°ì—¼/íœ˜ë°œì„±ì‚°ë„ ë¹„ìœ¨\n",
    "6. `acidity_balance` - ì‚°ë„ ê· í˜•\n",
    "7. `sugar_alcohol_ratio` - ë‹¹ë¶„/ì•Œì½”ì˜¬ ë¹„ìœ¨\n",
    "8. `alcohol_sulphates` - ì•Œì½”ì˜¬Ã—í™©ì‚°ì—¼ ìƒí˜¸ì‘ìš©\n",
    "\n",
    "### ê²°ë¡ \n",
    "- ì´ìƒì¹˜ ì²˜ë¦¬, íŠ¹ì„± ì—”ì§€ë‹ˆì–´ë§, í´ë˜ìŠ¤ ë¶ˆê· í˜• í•´ê²° ê¸°ë²•ì„ ì ìš©í•˜ì—¬ ëª¨ë¸ ì„±ëŠ¥ì„ ê°œì„ \n",
    "- class_weight ë˜ëŠ” SMOTEë¥¼ ì ìš©í•œ ëª¨ë¸ì´ ì›ë³¸ ëª¨ë¸ ëŒ€ë¹„ ì„±ëŠ¥ í–¥ìƒ ê°€ëŠ¥ì„± í™•ì¸\n",
    "- ì‹¤ì œ ì„±ëŠ¥ í–¥ìƒ ì •ë„ëŠ” ë°ì´í„° íŠ¹ì„±ê³¼ ëª¨ë¸ì— ë”°ë¼ ë‹¤ë¥¼ ìˆ˜ ìˆìŒ"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "DS",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.14"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
