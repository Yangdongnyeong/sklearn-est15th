{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Kaggle: Red Wine Quality (Cortez et al. 2009)\n",
    "\n",
    "이 노트북은 Kaggle의 Red Wine Quality 데이터셋(P. Cortez et al., 2009)을 활용하여 레드 와인의 품질을 예측하는 모델을 만드는 과정을 담고 있습니다.\n",
    "데이터셋은 UCI Machine Learning Repository에서 직접 다운로드하여 사용합니다.\n",
    "\n",
    "## 데이터셋 설명 (Dataset Description)\n",
    "\n",
    "- **데이터셋**: Red Wine Quality Dataset\n",
    "- **출처**: [Kaggle Link](https://www.kaggle.com/datasets/uciml/red-wine-quality-cortez-et-al-2009) / [UCI Link](https://archive.ics.uci.edu/ml/datasets/wine+quality)\n",
    "- **데이터 개수**: 1,599개\n",
    "- **특성(Features)**: 11개 (화학적 특성)\n",
    "- **타겟(Target)**: quality (0에서 10 사이의 점수)\n",
    "\n",
    "### 변수 설명 (Variables)\n",
    "1. **fixed acidity** (고정 산도): 와인의 산도와 관련된 고정된 산의 양\n",
    "2. **volatile acidity** (휘발성 산도): 와인에서 식초 맛을 내는 휘발성 산의 양 (너무 높으면 좋지 않음)\n",
    "3. **citric acid** (구연산): 와인의 신선함을 더해주는 산\n",
    "4. **residual sugar** (잔류 당분): 발효 후 남은 당분 (와인의 단맛 결정)\n",
    "5. **chlorides** (염화물): 와인 내 소금의 양\n",
    "6. **free sulfur dioxide** (유리 이산화황): 미생물 번식과 산화를 방지하는 SO2 형태\n",
    "7. **total sulfur dioxide** (총 이산화황): 유리형과 결합형 SO2의 총합\n",
    "8. **density** (밀도): 알코올 함량과 당분에 따라 달라지는 와인의 밀도\n",
    "9. **pH**: 와인의 산성도 (0: 강산성 ~ 14: 강알칼리성, 보통 3-4 사이)\n",
    "10. **sulphates** (황산염): 이산화황 농도에 영향을 주어 항균 및 항산화 작용을 함\n",
    "11. **alcohol** (알코올 도수): 와인의 알코올 함량 (% vol)\n",
    "12. **quality** (품질): 출력 변수 (0~10 사이의 점수, 3이 가장 낮고 8이 가장 높음)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d9e210b6",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "import urllib.request\n",
    "\n",
    "# 전처리 라이브러리\n",
    "from sklearn.model_selection import train_test_split, GridSearchCV, StratifiedKFold\n",
    "from sklearn.preprocessing import StandardScaler, LabelEncoder\n",
    "\n",
    "# 머신러닝 모델\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.tree import DecisionTreeClassifier\n",
    "from sklearn.ensemble import RandomForestClassifier, GradientBoostingClassifier, ExtraTreesClassifier, VotingClassifier, AdaBoostClassifier\n",
    "from sklearn.svm import SVC\n",
    "from sklearn.neighbors import KNeighborsClassifier\n",
    "# 평가 지표\n",
    "from sklearn.metrics import accuracy_score, classification_report, confusion_matrix, f1_score\n",
    "\n",
    "import warnings\n",
    "warnings.filterwarnings('ignore')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9ac38909",
   "metadata": {},
   "source": [
    "## 1. 데이터 로드 (Data Load)\n",
    "\n",
    "Kaggle에서 데이터를 직접 다운로드합니다."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "de8672ff",
   "metadata": {},
   "outputs": [],
   "source": [
    "# kaggle에 로그인을 해서 데이터셋을 다운로드 받기 위해\n",
    "# 로그인을 위한 키값을 설정\n",
    "from dotenv import load_dotenv\n",
    "# .env로 부터 파일을 읽으면 True가 출력\n",
    "print(load_dotenv())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5997caee",
   "metadata": {},
   "outputs": [],
   "source": [
    "#!/bin/bashkaggle\n",
    "!kaggle datasets download uciml/red-wine-quality-cortez-et-al-2009"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c410a533",
   "metadata": {},
   "outputs": [],
   "source": [
    "import zipfile\n",
    "import os\n",
    "# 압축 파일 경로 (정방향 슬래시 사용)\n",
    "zip_file_path = 'C:/Users/park/iCloudDrive/2025/EST_AI_MODEL_DEVEL/ESTSoft/DataScience/scikit-learn/red-wine-quality-cortez-et-al-2009.zip'\n",
    "# 압축을 풀 대상 디렉토리\n",
    "extract_to_path = 'C:/Users/park/iCloudDrive/2025/EST_AI_MODEL_DEVEL/ESTSoft/DataScience/scikit-learn/data'\n",
    "\n",
    "# zip 파일 열기 및 압축 해제\n",
    "with zipfile.ZipFile(zip_file_path, 'r') as zip_ref:\n",
    "    zip_ref.extractall(extract_to_path)\n",
    "    print(f\"압축 해제 완료: {extract_to_path}\")\n",
    "# 해제된 파일 목록 확인\n",
    "print(\"현재 폴더 파일 목록:\", os.listdir(extract_to_path))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7c689cbd",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "\n",
    "filename = os.path.join(extract_to_path, 'winequality-red.csv')\n",
    "# 세미콜론(;)으로 구분된 CSV 파일\n",
    "df = pd.read_csv(filename)\n",
    "df.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5af637f4",
   "metadata": {},
   "source": [
    "## 2. 데이터 분석 (EDA)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6ea98f40",
   "metadata": {},
   "outputs": [],
   "source": [
    "print(\"### Data Info ###\")\n",
    "print(df.info())\n",
    "# 다 수치형이면 전처리가 쉽다."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fc0ed73d",
   "metadata": {},
   "outputs": [],
   "source": [
    "print(\"\\n### Basic Statistics ###\")\n",
    "display(df.describe().round(4))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3760533b",
   "metadata": {},
   "outputs": [],
   "source": [
    "df['quality'].unique()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6a644736",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 타겟 변수(Quality) 분포 확인\n",
    "plt.figure(figsize=(8, 5))\n",
    "sns.countplot(x='quality', data=df, palette='viridis')\n",
    "plt.title(\"Red Wine Quality Distribution\")\n",
    "plt.show()\n",
    "\n",
    "# 상관관계 히트맵\n",
    "plt.figure(figsize=(10, 8))\n",
    "corr = df.corr()\n",
    "sns.heatmap(corr, annot=True, fmt='.2f', cmap='coolwarm', square=True)\n",
    "plt.title(\"Correlation Matrix\")\n",
    "plt.show()\n",
    "\n",
    "# quality 3, 4, 8은 데이터 수가 너무 작아 예측이 힘들다."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5d7eefd1",
   "metadata": {},
   "source": [
    "## 3. 데이터 전처리 및 특성 엔지니어링\n",
    "\n",
    "- **특성 엔지니어링**: 산도 관련 특성들을 합쳐서 `total acidity`를 만들어 봅니다 (선택 사항).\n",
    "- **이진 분류 변환 (선택)**: 원래 점수(0~10)를 그대로 쓸 수도 있지만, 보통 좋은 와인(예: 7 이상)과 나쁜 와인으로 나누거나 그대로 멀티 클래스로 분류합니다. 여기서는 **멀티 클래스 분류(각 점수별 예측)**를 수행하되, 데이터가 적은 클래스(3, 8 등)를 고려해야 합니다. \n",
    "  > 여기서는 **quality 그대로를 클래스로 사용하는 멀티클래스 분류**로 진행합니다.\n",
    "\n",
    "- **스케일링**: 대부분의 모델(SVM, KNN, Logistic 등)은 특성 스케일에 민감하므로 `StandardScaler`를 적용합니다."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "64874f9b",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 특성 엔지니어링 (예: 총 산도)\n",
    "# df['total_acidity'] = df['fixed acidity'] + df['volatile acidity'] + df['citric acid']\n",
    "# 이 예제에서는 원본 특성을 유지하며 진행합니다.\n",
    "\n",
    "X = df.drop('quality', axis=1)\n",
    "y = df['quality']\n",
    "\n",
    "# 타겟 클래스 개수가 적은 경우 (예: quality 3, 8) Stratified Split 사용 권장\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=42, stratify=y)\n",
    "\n",
    "# 스케일링\n",
    "scaler = StandardScaler()\n",
    "X_train_scaled = scaler.fit_transform(X_train)\n",
    "X_test_scaled = scaler.transform(X_test)\n",
    "\n",
    "print(f\"Train shape: {X_train_scaled.shape}, Test shape: {X_test_scaled.shape}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e5ae96ed",
   "metadata": {},
   "outputs": [],
   "source": [
    "# y_train에서 숫자별 데이터의 갯수 확인\n",
    "print(y_train.value_counts())\n",
    "print(y_test.value_counts())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1ca762da",
   "metadata": {},
   "outputs": [],
   "source": [
    "!pip install imbalanced-learn"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fb3fadc3",
   "metadata": {},
   "outputs": [],
   "source": [
    "from imblearn.over_sampling import SMOTE\n",
    "smote = SMOTE(random_state=42)\n",
    "X_train_res, y_train_res = smote.fit_resample(X_train_scaled, y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3f5b0816",
   "metadata": {},
   "outputs": [],
   "source": [
    "print(pd.Series(y_train[:]).value_counts())\n",
    "print(pd.Series(y_train_res[:]).value_counts())"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c51e0366",
   "metadata": {},
   "source": [
    "## 4. 모델링 (8가지 모델)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1f0df8f3",
   "metadata": {},
   "outputs": [],
   "source": [
    "models = {\n",
    "    'LogisticRegression': LogisticRegression(max_iter=2000, random_state=42),\n",
    "    'DecisionTree': DecisionTreeClassifier(random_state=42),\n",
    "    'RandomForest': RandomForestClassifier(random_state=42, class_weight='balanced_subsample'),\n",
    "    'SVM': SVC(probability=True, random_state=42),\n",
    "    'KNN': KNeighborsClassifier(),\n",
    "    'GradientBoosting': GradientBoostingClassifier(random_state=42),\n",
    "    'ExtraTrees': ExtraTreesClassifier(random_state=42),\n",
    "    'AdaBoost': AdaBoostClassifier(random_state=42)\n",
    "}\n",
    "\n",
    "results = {}\n",
    "print(\"### Initial Model Performance (Accuracy) ###\")\n",
    "for name, model in models.items():\n",
    "    #model.fit(X_train_scaled, y_train)\n",
    "    model.fit(X_train_res, y_train_res)\n",
    "    y_pred = model.predict(X_test_scaled)\n",
    "    acc = accuracy_score(y_test, y_pred)\n",
    "    results[name] = acc\n",
    "    print(f\"{name}: {acc:.4f}\")\n",
    "\n",
    "# 상위 4개 모델 선정\n",
    "sorted_results = sorted(results.items(), key=lambda x: x[1], reverse=True)\n",
    "top_4_names = [item[0] for item in sorted_results[:4]]\n",
    "print(f\"\\nTop 4 Models: {top_4_names}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "543f44de",
   "metadata": {},
   "source": [
    "## 5. 하이퍼 파라메터 튜닝 및 앙상블\n",
    "\n",
    "상위 4개 모델에 대해 `GridSearchCV` 또는 간단한 튜닝을 수행한 후, `VotingClassifier`로 앙상블합니다."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "806035a1",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Top 4 모델 객체 가져오기\n",
    "top_models = {}\n",
    "for name in top_4_names:\n",
    "    top_models[name] = models[name]\n",
    "\n",
    "# 튜닝을 위한 파라미터 그리드 예시 (시간 관계상 일부만 간단히 설정)\n",
    "param_grids = {\n",
    "    'RandomForest': {'n_estimators': [50, 100, 200, 300], 'max_depth': [10, 20, 25, None], 'class_weight':['balanced','balanced_subsample',None]},\n",
    "    'ExtraTrees': {'n_estimators': [50, 70, 100, 200], 'max_depth': [10, 20, 25, 30, None]},\n",
    "    'SVM': {'C': [1, 10], 'gamma': ['scale', 0.1]},\n",
    "    'GradientBoosting': {'n_estimators': [50, 75, 100, 200], 'learning_rate': [0.03, 0.05, 0.1]},\n",
    "    'KNN': {'n_neighbors': [3, 5, 7]},\n",
    "    'DecisionTree': {'max_depth': [5, 10, None]},\n",
    "    'LogisticRegression': {'C': [1, 10]},\n",
    "    'AdaBoost': {'n_estimators': [50, 100]}\n",
    "}\n",
    "\n",
    "tuned_estimators = []\n",
    "\n",
    "print(\"\\n### Hyperparameter Tuning for Top 4 ###\")\n",
    "for name in top_4_names:\n",
    "    if name in param_grids:\n",
    "        grid = GridSearchCV(top_models[name], param_grids[name], cv=3, n_jobs=-1, scoring='accuracy')\n",
    "        grid.fit(X_train_res, y_train_res)\n",
    "        best_model = grid.best_estimator_\n",
    "        print(f\"{name} Best Params: {grid.best_params_}, Score: {grid.best_score_:.4f}\")\n",
    "        tuned_estimators.append((name, best_model))\n",
    "    else:\n",
    "        # 튜닝할 파라미터가 없거나 설정 안된 경우 기본 모델 사용\n",
    "        tuned_estimators.append((name, top_models[name]))\n",
    "\n",
    "# 앙상블 모델 생성 (Hard Voting)\n",
    "ensemble_model = VotingClassifier(estimators=tuned_estimators, voting='hard')\n",
    "ensemble_model.fit(X_train_res, y_train_res)\n",
    "\n",
    "ensemble_pred = ensemble_model.predict(X_test_scaled)\n",
    "ensemble_acc = accuracy_score(y_test, ensemble_pred)\n",
    "\n",
    "print(f\"\\nEnsemble Model Test Accuracy: {ensemble_acc:.4f}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "akbcb6nekv",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 튜닝된 모델 중 가장 성능이 좋은 모델 찾기\n",
    "best_tuned_name = None\n",
    "best_tuned_score = 0\n",
    "best_tuned_model = None\n",
    "\n",
    "for name, model in tuned_estimators:\n",
    "    y_pred = model.predict(X_test_scaled)\n",
    "    acc = accuracy_score(y_test, y_pred)\n",
    "    print(f\"{name} Test Accuracy: {acc:.4f}\")\n",
    "    if acc > best_tuned_score:\n",
    "        best_tuned_score = acc\n",
    "        best_tuned_name = name\n",
    "        best_tuned_model = model\n",
    "\n",
    "print(f\"\\n최고 성능 모델: {best_tuned_name} (Accuracy: {best_tuned_score:.4f})\")\n",
    "\n",
    "# 최고 성능 모델의 Confusion Matrix 시각화\n",
    "best_pred = best_tuned_model.predict(X_test_scaled)\n",
    "labels = sorted(y_test.unique())\n",
    "\n",
    "print(f\"\\n### Confusion Matrix - {best_tuned_name} ###\")\n",
    "cm_best = confusion_matrix(y_test, best_pred)\n",
    "\n",
    "plt.figure(figsize=(8, 6))\n",
    "sns.heatmap(cm_best, \n",
    "            annot=True, \n",
    "            fmt='d', \n",
    "            cmap='Greens',\n",
    "            xticklabels=labels,\n",
    "            yticklabels=labels)\n",
    "plt.xlabel('Predicted')\n",
    "plt.ylabel('Actual')\n",
    "plt.title(f'Confusion Matrix - Best Model ({best_tuned_name})')\n",
    "plt.show()\n",
    "\n",
    "print(f\"\\n### Classification Report - {best_tuned_name} ###\")\n",
    "print(classification_report(y_test, best_pred))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c5d2c891",
   "metadata": {},
   "source": [
    "## 6. 모델 평가 및 결론"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cd032867",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 실제 클래스 라벨 추출 (3, 4, 5, 6, 7, 8)\n",
    "labels = sorted(y_test.unique())\n",
    "\n",
    "print(\"### Confusion Matrix ###\")\n",
    "cm = confusion_matrix(y_test, ensemble_pred)\n",
    "\n",
    "plt.figure(figsize=(8, 6))\n",
    "sns.heatmap(cm, \n",
    "            annot=True, \n",
    "            fmt='d', \n",
    "            cmap='Blues',\n",
    "            xticklabels=labels,  # x축에 3~8 표시\n",
    "            yticklabels=labels)  # y축에 3~8 표시\n",
    "plt.xlabel('Predicted')\n",
    "plt.ylabel('Actual')\n",
    "plt.title('Confusion Matrix - Ensemble Model')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "72847ff0",
   "metadata": {},
   "outputs": [],
   "source": [
    "print(y_train.value_counts())\n",
    "print(y_test.value_counts())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f7e073ba",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "DS",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.14"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
